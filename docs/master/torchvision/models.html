


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchvision.models &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/torchvision/models.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="torchvision.ops" href="ops.html" />
    <link rel="prev" title="torchvision.io" href="io.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.3.0a0+bf4a281 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/torchvision/models.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">torchvision</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">torchvision</a> &gt;</li>
        
      <li>torchvision.models</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/torchvision/models.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torchvision-models">
<h1>torchvision.models<a class="headerlink" href="#torchvision-models" title="Permalink to this headline">¶</a></h1>
<p>The models subpackage contains definitions of models for addressing
different tasks, including: image classification, pixelwise semantic
segmentation, object detection, instance segmentation, person
keypoint detection and video classification.</p>
<div class="section" id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h2>
<p>The models subpackage contains definitions for the following model
architectures for image classification:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1404.5997">AlexNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1409.1556">VGG</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1602.07360">SqueezeNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1608.06993">DenseNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1512.00567">Inception</a> v3</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1409.4842">GoogLeNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1807.11164">ShuffleNet</a> v2</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNet</a> v2</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1611.05431">ResNeXt</a></p></li>
<li><p><a class="reference internal" href="#wide-resnet">Wide ResNet</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1807.11626">MNASNet</a></p></li>
</ul>
<p>You can construct a model with random weights by calling its constructor:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="kn">as</span> <span class="nn">models</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">()</span>
<span class="n">vgg16</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span>
<span class="n">squeezenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">squeezenet1_0</span><span class="p">()</span>
<span class="n">densenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">densenet161</span><span class="p">()</span>
<span class="n">inception</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">inception_v3</span><span class="p">()</span>
<span class="n">googlenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">googlenet</span><span class="p">()</span>
<span class="n">shufflenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">shufflenet_v2_x1_0</span><span class="p">()</span>
<span class="n">mobilenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">mobilenet_v2</span><span class="p">()</span>
<span class="n">resnext50_32x4d</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnext50_32x4d</span><span class="p">()</span>
<span class="n">wide_resnet50_2</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">wide_resnet50_2</span><span class="p">()</span>
<span class="n">mnasnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">mnasnet1_0</span><span class="p">()</span>
</pre></div>
</div>
<p>We provide pre-trained models, using the PyTorch <a class="reference internal" href="../model_zoo.html#module-torch.utils.model_zoo" title="torch.utils.model_zoo"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.utils.model_zoo</span></code></a>.
These can be constructed by passing <code class="docutils literal notranslate"><span class="pre">pretrained=True</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="kn">as</span> <span class="nn">models</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">squeezenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">squeezenet1_0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">vgg16</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">densenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">densenet161</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">inception</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">inception_v3</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">googlenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">googlenet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">shufflenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">shufflenet_v2_x1_0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mobilenet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">resnext50_32x4d</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnext50_32x4d</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">wide_resnet50_2</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">wide_resnet50_2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">mnasnet</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">mnasnet1_0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Instancing a pre-trained model will download its weights to a cache directory.
This directory can be set using the <cite>TORCH_MODEL_ZOO</cite> environment variable. See
<a class="reference internal" href="../model_zoo.html#torch.utils.model_zoo.load_url" title="torch.utils.model_zoo.load_url"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.utils.model_zoo.load_url()</span></code></a> for details.</p>
<p>Some models use modules which have different training and evaluation
behavior, such as batch normalization. To switch between these modes, use
<code class="docutils literal notranslate"><span class="pre">model.train()</span></code> or <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> as appropriate. See
<a class="reference internal" href="../nn.html#torch.nn.Module.train" title="torch.nn.Module.train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">train()</span></code></a> or <a class="reference internal" href="../nn.html#torch.nn.Module.eval" title="torch.nn.Module.eval"><code class="xref py py-meth docutils literal notranslate"><span class="pre">eval()</span></code></a> for details.</p>
<p>All pre-trained models expect input images normalized in the same way,
i.e. mini-batches of 3-channel RGB images of shape (3 x H x W),
where H and W are expected to be at least 224.
The images have to be loaded in to a range of [0, 1] and then normalized
using <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></code>.
You can use the following transform to normalize:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</pre></div>
</div>
<p>An example of such normalization can be found in the imagenet example
<a class="reference external" href="https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101">here</a></p>
<p>ImageNet 1-crop error rates (224x224)</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>Top-1 error</p></th>
<th class="head"><p>Top-5 error</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>AlexNet</p></td>
<td><p>43.45</p></td>
<td><p>20.91</p></td>
</tr>
<tr class="row-odd"><td><p>VGG-11</p></td>
<td><p>30.98</p></td>
<td><p>11.37</p></td>
</tr>
<tr class="row-even"><td><p>VGG-13</p></td>
<td><p>30.07</p></td>
<td><p>10.75</p></td>
</tr>
<tr class="row-odd"><td><p>VGG-16</p></td>
<td><p>28.41</p></td>
<td><p>9.62</p></td>
</tr>
<tr class="row-even"><td><p>VGG-19</p></td>
<td><p>27.62</p></td>
<td><p>9.12</p></td>
</tr>
<tr class="row-odd"><td><p>VGG-11 with batch normalization</p></td>
<td><p>29.62</p></td>
<td><p>10.19</p></td>
</tr>
<tr class="row-even"><td><p>VGG-13 with batch normalization</p></td>
<td><p>28.45</p></td>
<td><p>9.63</p></td>
</tr>
<tr class="row-odd"><td><p>VGG-16 with batch normalization</p></td>
<td><p>26.63</p></td>
<td><p>8.50</p></td>
</tr>
<tr class="row-even"><td><p>VGG-19 with batch normalization</p></td>
<td><p>25.76</p></td>
<td><p>8.15</p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-18</p></td>
<td><p>30.24</p></td>
<td><p>10.92</p></td>
</tr>
<tr class="row-even"><td><p>ResNet-34</p></td>
<td><p>26.70</p></td>
<td><p>8.58</p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-50</p></td>
<td><p>23.85</p></td>
<td><p>7.13</p></td>
</tr>
<tr class="row-even"><td><p>ResNet-101</p></td>
<td><p>22.63</p></td>
<td><p>6.44</p></td>
</tr>
<tr class="row-odd"><td><p>ResNet-152</p></td>
<td><p>21.69</p></td>
<td><p>5.94</p></td>
</tr>
<tr class="row-even"><td><p>SqueezeNet 1.0</p></td>
<td><p>41.90</p></td>
<td><p>19.58</p></td>
</tr>
<tr class="row-odd"><td><p>SqueezeNet 1.1</p></td>
<td><p>41.81</p></td>
<td><p>19.38</p></td>
</tr>
<tr class="row-even"><td><p>Densenet-121</p></td>
<td><p>25.35</p></td>
<td><p>7.83</p></td>
</tr>
<tr class="row-odd"><td><p>Densenet-169</p></td>
<td><p>24.00</p></td>
<td><p>7.00</p></td>
</tr>
<tr class="row-even"><td><p>Densenet-201</p></td>
<td><p>22.80</p></td>
<td><p>6.43</p></td>
</tr>
<tr class="row-odd"><td><p>Densenet-161</p></td>
<td><p>22.35</p></td>
<td><p>6.20</p></td>
</tr>
<tr class="row-even"><td><p>Inception v3</p></td>
<td><p>22.55</p></td>
<td><p>6.44</p></td>
</tr>
<tr class="row-odd"><td><p>GoogleNet</p></td>
<td><p>30.22</p></td>
<td><p>10.47</p></td>
</tr>
<tr class="row-even"><td><p>ShuffleNet V2</p></td>
<td><p>30.64</p></td>
<td><p>11.68</p></td>
</tr>
<tr class="row-odd"><td><p>MobileNet V2</p></td>
<td><p>28.12</p></td>
<td><p>9.71</p></td>
</tr>
<tr class="row-even"><td><p>ResNeXt-50-32x4d</p></td>
<td><p>22.38</p></td>
<td><p>6.30</p></td>
</tr>
<tr class="row-odd"><td><p>ResNeXt-101-32x8d</p></td>
<td><p>20.69</p></td>
<td><p>5.47</p></td>
</tr>
<tr class="row-even"><td><p>Wide ResNet-50-2</p></td>
<td><p>21.49</p></td>
<td><p>5.91</p></td>
</tr>
<tr class="row-odd"><td><p>Wide ResNet-101-2</p></td>
<td><p>21.16</p></td>
<td><p>5.72</p></td>
</tr>
<tr class="row-even"><td><p>MNASNet 1.0</p></td>
<td><p>26.49</p></td>
<td><p>8.456</p></td>
</tr>
</tbody>
</table>
<div class="section" id="id1">
<h3>Alexnet<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id2">
<h3>VGG<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id3">
<h3>ResNet<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id4">
<h3>SqueezeNet<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id5">
<h3>DenseNet<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="inception-v3">
<h3>Inception v3<a class="headerlink" href="#inception-v3" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id6">
<h3>GoogLeNet<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="shufflenet-v2">
<h3>ShuffleNet v2<a class="headerlink" href="#shufflenet-v2" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="mobilenet-v2">
<h3>MobileNet v2<a class="headerlink" href="#mobilenet-v2" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id7">
<h3>ResNext<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="wide-resnet">
<h3>Wide ResNet<a class="headerlink" href="#wide-resnet" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id8">
<h3>MNASNet<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="semantic-segmentation">
<h2>Semantic Segmentation<a class="headerlink" href="#semantic-segmentation" title="Permalink to this headline">¶</a></h2>
<p>The models subpackage contains definitions for the following model
architectures for semantic segmentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1411.4038">FCN ResNet101</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.05587">DeepLabV3 ResNet101</a></p></li>
</ul>
<p>As with image classification models, all pre-trained models expect input images normalized in the same way.
The images have to be loaded in to a range of <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code> and then normalized using
<code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></code>.
They have been trained on images resized such that their minimum size is 520.</p>
<p>The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are
present in the Pascal VOC dataset. You can see more information on how the subset has been selected in
<code class="docutils literal notranslate"><span class="pre">references/segmentation/coco_utils.py</span></code>. The classes that the pre-trained model outputs are the following,
in order:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;__background__&#39;</span><span class="p">,</span> <span class="s1">&#39;aeroplane&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;boat&#39;</span><span class="p">,</span> <span class="s1">&#39;bottle&#39;</span><span class="p">,</span> <span class="s1">&#39;bus&#39;</span><span class="p">,</span>
 <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;chair&#39;</span><span class="p">,</span> <span class="s1">&#39;cow&#39;</span><span class="p">,</span> <span class="s1">&#39;diningtable&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;motorbike&#39;</span><span class="p">,</span>
 <span class="s1">&#39;person&#39;</span><span class="p">,</span> <span class="s1">&#39;pottedplant&#39;</span><span class="p">,</span> <span class="s1">&#39;sheep&#39;</span><span class="p">,</span> <span class="s1">&#39;sofa&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;tvmonitor&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p>The accuracies of the pre-trained models evaluated on COCO val2017 are as follows</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 49%" />
<col style="width: 20%" />
<col style="width: 31%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>mean IoU</p></th>
<th class="head"><p>global pixelwise acc</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>FCN ResNet101</p></td>
<td><p>63.7</p></td>
<td><p>91.9</p></td>
</tr>
<tr class="row-odd"><td><p>DeepLabV3 ResNet101</p></td>
<td><p>67.4</p></td>
<td><p>92.4</p></td>
</tr>
</tbody>
</table>
<div class="section" id="fully-convolutional-networks">
<h3>Fully Convolutional Networks<a class="headerlink" href="#fully-convolutional-networks" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchvision.models.segmentation.fcn_resnet50">
<code class="sig-prename descclassname">torchvision.models.segmentation.</code><code class="sig-name descname">fcn_resnet50</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">progress=True</em>, <em class="sig-param">num_classes=21</em>, <em class="sig-param">aux_loss=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchvision/models/segmentation/segmentation.html#fcn_resnet50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.models.segmentation.fcn_resnet50" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a Fully-Convolutional Network model with a ResNet-50 backbone.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, returns a model pre-trained on COCO train2017 which
contains the same classes as Pascal VOC</p></li>
<li><p><strong>progress</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, displays a progress bar of the download to stderr</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torchvision.models.segmentation.fcn_resnet101">
<code class="sig-prename descclassname">torchvision.models.segmentation.</code><code class="sig-name descname">fcn_resnet101</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">progress=True</em>, <em class="sig-param">num_classes=21</em>, <em class="sig-param">aux_loss=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchvision/models/segmentation/segmentation.html#fcn_resnet101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.models.segmentation.fcn_resnet101" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a Fully-Convolutional Network model with a ResNet-101 backbone.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, returns a model pre-trained on COCO train2017 which
contains the same classes as Pascal VOC</p></li>
<li><p><strong>progress</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, displays a progress bar of the download to stderr</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="deeplabv3">
<h3>DeepLabV3<a class="headerlink" href="#deeplabv3" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torchvision.models.segmentation.deeplabv3_resnet50">
<code class="sig-prename descclassname">torchvision.models.segmentation.</code><code class="sig-name descname">deeplabv3_resnet50</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">progress=True</em>, <em class="sig-param">num_classes=21</em>, <em class="sig-param">aux_loss=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchvision/models/segmentation/segmentation.html#deeplabv3_resnet50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.models.segmentation.deeplabv3_resnet50" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a DeepLabV3 model with a ResNet-50 backbone.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, returns a model pre-trained on COCO train2017 which
contains the same classes as Pascal VOC</p></li>
<li><p><strong>progress</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, displays a progress bar of the download to stderr</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torchvision.models.segmentation.deeplabv3_resnet101">
<code class="sig-prename descclassname">torchvision.models.segmentation.</code><code class="sig-name descname">deeplabv3_resnet101</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">progress=True</em>, <em class="sig-param">num_classes=21</em>, <em class="sig-param">aux_loss=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchvision/models/segmentation/segmentation.html#deeplabv3_resnet101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.models.segmentation.deeplabv3_resnet101" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a DeepLabV3 model with a ResNet-101 backbone.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, returns a model pre-trained on COCO train2017 which
contains the same classes as Pascal VOC</p></li>
<li><p><strong>progress</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If True, displays a progress bar of the download to stderr</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="object-detection-instance-segmentation-and-person-keypoint-detection">
<h2>Object Detection, Instance Segmentation and Person Keypoint Detection<a class="headerlink" href="#object-detection-instance-segmentation-and-person-keypoint-detection" title="Permalink to this headline">¶</a></h2>
<p>The models subpackage contains definitions for the following model
architectures for detection:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN ResNet-50 FPN</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN ResNet-50 FPN</a></p></li>
</ul>
<p>The pre-trained models for detection, instance segmentation and
keypoint detection are initialized with the classification models
in torchvision.</p>
<p>The models expect a list of <code class="docutils literal notranslate"><span class="pre">Tensor[C,</span> <span class="pre">H,</span> <span class="pre">W]</span></code>, in the range <code class="docutils literal notranslate"><span class="pre">0-1</span></code>.
The models internally resize the images so that they have a minimum size
of <code class="docutils literal notranslate"><span class="pre">800</span></code>. This option can be changed by passing the option <code class="docutils literal notranslate"><span class="pre">min_size</span></code>
to the constructor of the models.</p>
<p>For object detection and instance segmentation, the pre-trained
models return the predictions of the following classes:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COCO_INSTANCE_CATEGORY_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;__background__&#39;</span><span class="p">,</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;motorcycle&#39;</span><span class="p">,</span> <span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;bus&#39;</span><span class="p">,</span>
    <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">,</span> <span class="s1">&#39;boat&#39;</span><span class="p">,</span> <span class="s1">&#39;traffic light&#39;</span><span class="p">,</span> <span class="s1">&#39;fire hydrant&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;stop sign&#39;</span><span class="p">,</span>
    <span class="s1">&#39;parking meter&#39;</span><span class="p">,</span> <span class="s1">&#39;bench&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;sheep&#39;</span><span class="p">,</span> <span class="s1">&#39;cow&#39;</span><span class="p">,</span>
    <span class="s1">&#39;elephant&#39;</span><span class="p">,</span> <span class="s1">&#39;bear&#39;</span><span class="p">,</span> <span class="s1">&#39;zebra&#39;</span><span class="p">,</span> <span class="s1">&#39;giraffe&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;backpack&#39;</span><span class="p">,</span> <span class="s1">&#39;umbrella&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span>
    <span class="s1">&#39;handbag&#39;</span><span class="p">,</span> <span class="s1">&#39;tie&#39;</span><span class="p">,</span> <span class="s1">&#39;suitcase&#39;</span><span class="p">,</span> <span class="s1">&#39;frisbee&#39;</span><span class="p">,</span> <span class="s1">&#39;skis&#39;</span><span class="p">,</span> <span class="s1">&#39;snowboard&#39;</span><span class="p">,</span> <span class="s1">&#39;sports ball&#39;</span><span class="p">,</span>
    <span class="s1">&#39;kite&#39;</span><span class="p">,</span> <span class="s1">&#39;baseball bat&#39;</span><span class="p">,</span> <span class="s1">&#39;baseball glove&#39;</span><span class="p">,</span> <span class="s1">&#39;skateboard&#39;</span><span class="p">,</span> <span class="s1">&#39;surfboard&#39;</span><span class="p">,</span> <span class="s1">&#39;tennis racket&#39;</span><span class="p">,</span>
    <span class="s1">&#39;bottle&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;wine glass&#39;</span><span class="p">,</span> <span class="s1">&#39;cup&#39;</span><span class="p">,</span> <span class="s1">&#39;fork&#39;</span><span class="p">,</span> <span class="s1">&#39;knife&#39;</span><span class="p">,</span> <span class="s1">&#39;spoon&#39;</span><span class="p">,</span> <span class="s1">&#39;bowl&#39;</span><span class="p">,</span>
    <span class="s1">&#39;banana&#39;</span><span class="p">,</span> <span class="s1">&#39;apple&#39;</span><span class="p">,</span> <span class="s1">&#39;sandwich&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;broccoli&#39;</span><span class="p">,</span> <span class="s1">&#39;carrot&#39;</span><span class="p">,</span> <span class="s1">&#39;hot dog&#39;</span><span class="p">,</span> <span class="s1">&#39;pizza&#39;</span><span class="p">,</span>
    <span class="s1">&#39;donut&#39;</span><span class="p">,</span> <span class="s1">&#39;cake&#39;</span><span class="p">,</span> <span class="s1">&#39;chair&#39;</span><span class="p">,</span> <span class="s1">&#39;couch&#39;</span><span class="p">,</span> <span class="s1">&#39;potted plant&#39;</span><span class="p">,</span> <span class="s1">&#39;bed&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;dining table&#39;</span><span class="p">,</span>
    <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;toilet&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;tv&#39;</span><span class="p">,</span> <span class="s1">&#39;laptop&#39;</span><span class="p">,</span> <span class="s1">&#39;mouse&#39;</span><span class="p">,</span> <span class="s1">&#39;remote&#39;</span><span class="p">,</span> <span class="s1">&#39;keyboard&#39;</span><span class="p">,</span> <span class="s1">&#39;cell phone&#39;</span><span class="p">,</span>
    <span class="s1">&#39;microwave&#39;</span><span class="p">,</span> <span class="s1">&#39;oven&#39;</span><span class="p">,</span> <span class="s1">&#39;toaster&#39;</span><span class="p">,</span> <span class="s1">&#39;sink&#39;</span><span class="p">,</span> <span class="s1">&#39;refrigerator&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span>
    <span class="s1">&#39;clock&#39;</span><span class="p">,</span> <span class="s1">&#39;vase&#39;</span><span class="p">,</span> <span class="s1">&#39;scissors&#39;</span><span class="p">,</span> <span class="s1">&#39;teddy bear&#39;</span><span class="p">,</span> <span class="s1">&#39;hair drier&#39;</span><span class="p">,</span> <span class="s1">&#39;toothbrush&#39;</span>
<span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p>Here are the summary of the accuracies for the models trained on
the instances set of COCO train2017 and evaluated on COCO val2017.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 12%" />
<col style="width: 14%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>box AP</p></th>
<th class="head"><p>mask AP</p></th>
<th class="head"><p>keypoint AP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Faster R-CNN ResNet-50 FPN</p></td>
<td><p>37.0</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><ul class="simple">
<li></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p>Mask R-CNN ResNet-50 FPN</p></td>
<td><p>37.9</p></td>
<td><p>34.6</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>For person keypoint detection, the accuracies for the pre-trained
models are as follows</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 12%" />
<col style="width: 14%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>box AP</p></th>
<th class="head"><p>mask AP</p></th>
<th class="head"><p>keypoint AP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Keypoint R-CNN ResNet-50 FPN</p></td>
<td><p>54.6</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>65.0</p></td>
</tr>
</tbody>
</table>
<p>For person keypoint detection, the pre-trained model return the
keypoints in the following order:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">COCO_PERSON_KEYPOINT_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;nose&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_eye&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_eye&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_ear&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_ear&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_shoulder&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_shoulder&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_elbow&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_elbow&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_wrist&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_wrist&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_hip&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_hip&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_knee&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_knee&#39;</span><span class="p">,</span>
    <span class="s1">&#39;left_ankle&#39;</span><span class="p">,</span>
    <span class="s1">&#39;right_ankle&#39;</span>
<span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<div class="section" id="runtime-characteristics">
<h3>Runtime characteristics<a class="headerlink" href="#runtime-characteristics" title="Permalink to this headline">¶</a></h3>
<p>The implementations of the models for object detection, instance segmentation
and keypoint detection are efficient.</p>
<p>In the following table, we use 8 V100 GPUs, with CUDA 10.0 and CUDNN 7.4 to
report the results. During training, we use a batch size of 2 per GPU, and
during testing a batch size of 1 is used.</p>
<p>For test time, we report the time for the model evaluation and postprocessing
(including mask pasting in image), but not the time for computing the
precision-recall.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 38%" />
<col style="width: 24%" />
<col style="width: 23%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>train time (s / it)</p></th>
<th class="head"><p>test time (s / it)</p></th>
<th class="head"><p>memory (GB)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Faster R-CNN ResNet-50 FPN</p></td>
<td><p>0.2288</p></td>
<td><p>0.0590</p></td>
<td><p>5.2</p></td>
</tr>
<tr class="row-odd"><td><p>Mask R-CNN ResNet-50 FPN</p></td>
<td><p>0.2728</p></td>
<td><p>0.0903</p></td>
<td><p>5.4</p></td>
</tr>
<tr class="row-even"><td><p>Keypoint R-CNN ResNet-50 FPN</p></td>
<td><p>0.3789</p></td>
<td><p>0.1242</p></td>
<td><p>6.8</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="faster-r-cnn">
<h3>Faster R-CNN<a class="headerlink" href="#faster-r-cnn" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="mask-r-cnn">
<h3>Mask R-CNN<a class="headerlink" href="#mask-r-cnn" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="keypoint-r-cnn">
<h3>Keypoint R-CNN<a class="headerlink" href="#keypoint-r-cnn" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="video-classification">
<h2>Video classification<a class="headerlink" href="#video-classification" title="Permalink to this headline">¶</a></h2>
<p>We provide models for action recognition pre-trained on Kinetics-400.
They have all been trained with the scripts provided in <code class="docutils literal notranslate"><span class="pre">references/video_classification</span></code>.</p>
<p>All pre-trained models expect input images normalized in the same way,
i.e. mini-batches of 3-channel RGB videos of shape (3 x T x H x W),
where H and W are expected to be 112, and T is a number of video frames in a clip.
The images have to be loaded in to a range of [0, 1] and then normalized
using <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.43216,</span> <span class="pre">0.394666,</span> <span class="pre">0.37645]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.22803,</span> <span class="pre">0.22145,</span> <span class="pre">0.216989]</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The normalization parameters are different from the image classification ones, and correspond
to the mean and std from Kinetics-400.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For now, normalization code can be found in <code class="docutils literal notranslate"><span class="pre">references/video_classification/transforms.py</span></code>,
see the <code class="docutils literal notranslate"><span class="pre">Normalize</span></code> function there. Note that it differs from standard normalization for
images because it assumes the video is 4d.</p>
</div>
<p>Kinetics 1-crop accuracies for clip length 16 (16x112x112)</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 55%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Network</p></th>
<th class="head"><p>Clip acc&#64;1</p></th>
<th class="head"><p>Clip acc&#64;5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ResNet 3D 18</p></td>
<td><p>52.75</p></td>
<td><p>75.45</p></td>
</tr>
<tr class="row-odd"><td><p>ResNet MC 18</p></td>
<td><p>53.90</p></td>
<td><p>76.29</p></td>
</tr>
<tr class="row-even"><td><p>ResNet (2+1)D</p></td>
<td><p>57.50</p></td>
<td><p>78.81</p></td>
</tr>
</tbody>
</table>
<div class="section" id="resnet-3d">
<h3>ResNet 3D<a class="headerlink" href="#resnet-3d" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="resnet-mixed-convolution">
<h3>ResNet Mixed Convolution<a class="headerlink" href="#resnet-mixed-convolution" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="resnet-2-1-d">
<h3>ResNet (2+1)D<a class="headerlink" href="#resnet-2-1-d" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ops.html" class="btn btn-neutral float-right" title="torchvision.ops" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="io.html" class="btn btn-neutral" title="torchvision.io" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchvision.models</a><ul>
<li><a class="reference internal" href="#classification">Classification</a><ul>
<li><a class="reference internal" href="#id1">Alexnet</a></li>
<li><a class="reference internal" href="#id2">VGG</a></li>
<li><a class="reference internal" href="#id3">ResNet</a></li>
<li><a class="reference internal" href="#id4">SqueezeNet</a></li>
<li><a class="reference internal" href="#id5">DenseNet</a></li>
<li><a class="reference internal" href="#inception-v3">Inception v3</a></li>
<li><a class="reference internal" href="#id6">GoogLeNet</a></li>
<li><a class="reference internal" href="#shufflenet-v2">ShuffleNet v2</a></li>
<li><a class="reference internal" href="#mobilenet-v2">MobileNet v2</a></li>
<li><a class="reference internal" href="#id7">ResNext</a></li>
<li><a class="reference internal" href="#wide-resnet">Wide ResNet</a></li>
<li><a class="reference internal" href="#id8">MNASNet</a></li>
</ul>
</li>
<li><a class="reference internal" href="#semantic-segmentation">Semantic Segmentation</a><ul>
<li><a class="reference internal" href="#fully-convolutional-networks">Fully Convolutional Networks</a></li>
<li><a class="reference internal" href="#deeplabv3">DeepLabV3</a></li>
</ul>
</li>
<li><a class="reference internal" href="#object-detection-instance-segmentation-and-person-keypoint-detection">Object Detection, Instance Segmentation and Person Keypoint Detection</a><ul>
<li><a class="reference internal" href="#runtime-characteristics">Runtime characteristics</a></li>
<li><a class="reference internal" href="#faster-r-cnn">Faster R-CNN</a></li>
<li><a class="reference internal" href="#mask-r-cnn">Mask R-CNN</a></li>
<li><a class="reference internal" href="#keypoint-r-cnn">Keypoint R-CNN</a></li>
</ul>
</li>
<li><a class="reference internal" href="#video-classification">Video classification</a><ul>
<li><a class="reference internal" href="#resnet-3d">ResNet 3D</a></li>
<li><a class="reference internal" href="#resnet-mixed-convolution">ResNet Mixed Convolution</a></li>
<li><a class="reference internal" href="#resnet-2-1-d">ResNet (2+1)D</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script type="text/javascript" src="../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>
  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>